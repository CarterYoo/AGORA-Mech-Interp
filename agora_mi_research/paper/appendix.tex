\appendix

\section{Experimental Details}
\label{app:details}

\subsection{Data Processing}

\textbf{Stratified Sampling Algorithm.}

\begin{algorithm}[h]
\caption{Multi-dimensional Stratified Sampling}
\begin{algorithmic}[1]
\REQUIRE Documents $\mathcal{D}$, target size $n$, stratification factors $\mathcal{F}$
\ENSURE Sampled documents $\mathcal{D}_s$ with balanced representation
\STATE Initialize $\mathcal{D}_s \leftarrow \emptyset$
\FOR{each authority $a$ in authorities}
    \STATE $n_a \leftarrow \text{proportional\_target}(a, n)$
    \STATE $\mathcal{D}_a \leftarrow \{d \in \mathcal{D} : d.authority = a\}$
    \FOR{each length category $\ell$ in \{short, medium, long\}}
        \STATE $n_{a,\ell} \leftarrow n_a \times \text{length\_proportion}(\ell)$
        \STATE $\mathcal{D}_{a,\ell} \leftarrow \{d \in \mathcal{D}_a : d.length\_cat = \ell\}$
        \STATE $\mathcal{D}_s \leftarrow \mathcal{D}_s \cup \text{random\_sample}(\mathcal{D}_{a,\ell}, n_{a,\ell})$
    \ENDFOR
\ENDFOR
\RETURN $\mathcal{D}_s$
\end{algorithmic}
\end{algorithm}

\subsection{Hallucination Annotation Schema}

Following RAGTruth \cite{wu2024ragtruth}, we define four hallucination categories:

\textbf{Category 1: Evident Baseless Info.} Clear fabrications without any support in retrieved context. 

\textit{Example}: "The EU AI Act bans all facial recognition systems" when context discusses regulation framework without mentioning outright bans.

\textbf{Category 2: Subtle Conflict.} Minor contradictions or inconsistencies with retrieved information.

\textit{Example}: "The act applies to all AI systems" when context specifies "high-risk AI systems."

\textbf{Category 3: Nuanced Misrepresentation.} Subtle distortions that change meaning.

\textit{Example}: Changing "should consider" to "must implement" when paraphrasing regulatory language.

\textbf{Category 4: Reasoning Error.} Incorrect logical inferences from context.

\textit{Example}: Concluding causation from correlational statements in policy documents.

\subsection{AARF Intervention Algorithm}

\textbf{Intervention Pseudocode.}

\begin{algorithm}[h]
\caption{AARF Intervention Application}
\begin{algorithmic}[1]
\REQUIRE Model $M$, question $q$, context $C$, threshold $\theta$, copying heads $\mathcal{H}$
\ENSURE Baseline response $y_b$, AARF response $y_a$
\STATE Generate baseline: $y_b \leftarrow M(q, C)$
\STATE Extract attention tensors $\mathbf{A}$ and hidden states $\mathbf{H}$
\STATE Compute ECS and PKS trajectories
\FOR{each generated token $t$}
    \STATE $h_{\text{score}}(t) \leftarrow \alpha \cdot (1 - \text{ECS}(t)) + \beta \cdot \text{PKS}(t)$
    \IF{$h_{\text{score}}(t) \geq \theta$}
        \STATE Trigger intervention flag
    \ENDIF
\ENDFOR
\IF{intervention flag is True}
    \STATE Register attention hooks: $\forall (l,h) \in \mathcal{H}: A_{l,h}(t, i) \leftarrow \gamma \cdot A_{l,h}(t, i)$ for $i \in C$
    \STATE Register FFN hooks: $\forall l: \mathbf{h}_{\text{FFN}}^{(l)} \leftarrow \delta \cdot \mathbf{h}_{\text{FFN}}^{(l)}$
    \STATE Regenerate: $y_a \leftarrow M(q, C)$ with hooks active
    \STATE Remove all hooks
\ELSE
    \STATE $y_a \leftarrow y_b$ (no intervention needed)
\ENDIF
\RETURN $y_b, y_a$
\end{algorithmic}
\end{algorithm}

\subsection{Data Collection Architecture}

\textbf{Storage Structure.} Our comprehensive data collection system organizes MI data hierarchically:

\begin{itemize}
    \item \textbf{Attention Data}: Full attention tensors stored in HDF5 format for efficient I/O. Each file contains per-generation-step attention matrices $[L, H, S, S]$.
    \item \textbf{Trajectory Data}: ECS and PKS trajectories stored as NumPy arrays, enabling fast statistical analysis.
    \item \textbf{Metadata}: JSON files containing aggregated statistics, copying head identification, and intervention events.
\end{itemize}

\textbf{Query Interface.} The MIDataCollector provides methods to:
\begin{itemize}
    \item Load full attention tensors for specific responses
    \item Access ECS/PKS trajectories for analysis
    \item Retrieve intervention event logs
    \item Query aggregated statistics across responses
\end{itemize}

\subsection{Visualization Details}

\textbf{Figure Types.} We generate the following visualization types:

\begin{itemize}
    \item \textbf{Attention Heatmaps}: Layer $\times$ head attention to context, with copying heads highlighted
    \item \textbf{Trajectory Plots}: ECS/PKS evolution over generation steps
    \item \textbf{Scatter Plots}: ECS vs PKS with color coding by hallucination status
    \item \textbf{Intervention Analysis}: Before/after attention weight comparisons
    \item \textbf{Logit Lens Plots}: Layer-wise prediction evolution
\end{itemize}

All figures are generated at publication quality (300 DPI) with consistent styling following ACL format guidelines.

\subsection{Annotation Protocol}

\textbf{Annotator Training.} Two expert annotators with legal backgrounds complete:
\begin{enumerate}
    \item 2-hour training session on hallucination categories
    \item Practice annotation on 10 pilot examples with discussion
    \item Calibration session to align judgment criteria
\end{enumerate}

\textbf{Annotation Process.}
\begin{enumerate}
    \item Read question and retrieved context carefully
    \item Read generated response
    \item Mark hallucination spans at word level
    \item Assign category and severity (High/Medium/Low)
    \item Rate overall response quality
    \item Provide free-text notes
\end{enumerate}

\textbf{Quality Control.}
\begin{itemize}
    \item Dual annotation for 20\% of data
    \item Inter-annotator agreement: Cohen's $\kappa$ (target: $\kappa > 0.7$)
    \item Disagreement adjudication through discussion
    \item Minimum annotation time: 60 seconds per response
\end{itemize}

\subsection{Hyperparameter Sensitivity}

We test ECS threshold sensitivity for copying head identification:

\begin{table}[h]
\centering
\small
\begin{tabular}{lcc}
\toprule
Threshold & Num Heads & Correlation with Accuracy \\
\midrule
0.2 & TBD & TBD \\
0.3 & TBD & TBD \\
0.4 & TBD & TBD \\
\bottomrule
\end{tabular}
\caption{Copying head threshold sensitivity.}
\end{table}

\section{Additional Results}
\label{app:results}

\subsection{Layer-wise ECS Analysis}

Figure \ref{fig:layer_ecs} shows ECS evolution across transformer layers for hallucinated vs non-hallucinated responses.

\begin{figure}[h]
\centering
\includegraphics[width=0.45\textwidth]{figures/layer_wise_ecs.pdf}
\caption{Layer-wise ECS for hallucinated (red) vs non-hallucinated (blue) responses. Error bars show 95\% bootstrap CI. Middle layers (12-20) show highest context attention.}
\label{fig:layer_ecs}
\end{figure}

\subsection{Task-specific Analysis}

Hallucination rates and MI metrics broken down by task type:

\begin{table}[h]
\centering
\small
\begin{tabular}{lcccc}
\toprule
Task Type & N & Hall. Rate & Mean ECS & Mean PKS \\
\midrule
QA & TBD & TBD\% & TBD & TBD \\
Data2txt & TBD & TBD\% & TBD & TBD \\
Summarization & TBD & TBD\% & TBD & TBD \\
\bottomrule
\end{tabular}
\caption{Task-specific hallucination rates and MI metrics.}
\end{table}

\subsection{Authority-specific Analysis}

Performance breakdown by jurisdiction:

\begin{table}[h]
\centering
\small
\begin{tabular}{lcccc}
\toprule
Authority & N & Hall. Rate & Mean ECS & Mean PKS \\
\midrule
EU & TBD & TBD\% & TBD & TBD \\
US & TBD & TBD\% & TBD & TBD \\
UK & TBD & TBD\% & TBD & TBD \\
Canada & TBD & TBD\% & TBD & TBD \\
Others & TBD & TBD\% & TBD & TBD \\
\bottomrule
\end{tabular}
\caption{Authority-specific performance metrics.}
\end{table}

\subsection{Confusion Matrices}

Confusion matrices for ECS-based hallucination detection at optimal threshold:

\begin{table}[h]
\centering
\small
\begin{tabular}{cc|cc}
\toprule
 & & \multicolumn{2}{c}{Predicted} \\
 & & No Hall. & Hallucination \\
\midrule
\multirow{2}{*}{Actual} & No Hall. & TBD & TBD \\
& Hallucination & TBD & TBD \\
\bottomrule
\end{tabular}
\caption{Confusion matrix for ECS-based detection.}
\end{table}

\subsection{Attention Visualization}

Detailed attention heatmaps for representative examples:

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figures/attention_heatmap.pdf}
\caption{Attention heatmap showing token-to-token attention for (top) factual response with high ECS and (bottom) hallucinated response with low ECS. Context tokens marked in blue.}
\label{fig:attention}
\end{figure}

\section{Implementation Details}
\label{app:implementation}

\subsection{ColBERT Configuration}

\begin{verbatim}
ColBERTConfig:
  checkpoint: "colbert-ir/colbertv2.0"
  doc_maxlen: 300
  query_maxlen: 32
  nbits: 2  # compression
  kmeans_niters: 4
\end{verbatim}

\subsection{Model Configuration}

\begin{verbatim}
Model: mistralai/Mistral-7B-Instruct-v0.2
Quantization: 4-bit (BitsAndBytes NF4)
Context length: 2048 tokens
Parameters:
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  repetition_penalty: 1.1
  max_new_tokens: 512
\end{verbatim}

\subsection{Computational Requirements}

\begin{itemize}
    \item \textbf{Data Processing}: < 5 minutes on single CPU
    \item \textbf{ColBERT Indexing}: 20-30 minutes on GPU (one-time)
    \item \textbf{RAG Generation}: 30-90 seconds per question
    \item \textbf{MI Analysis}: 10-15 seconds per response
    \item \textbf{Total Pipeline}: 1-3 hours for 200 questions
\end{itemize}

\subsection{Code Availability}

Complete implementation available at:
\begin{verbatim}
https://github.com/[anonymous]/agora_mi_research
\end{verbatim}

Directory structure:
\begin{verbatim}
agora_mi_research/
├── src/
│   ├── data/          # Data loading and preprocessing
│   ├── rag/           # RAG pipeline components
│   ├── mi/            # MI analysis modules
│   ├── annotation/    # Annotation tools
│   └── evaluation/    # Metrics and statistics
├── experiments/       # Experimental scripts
├── configs/           # Configuration files
└── docs/              # Documentation
\end{verbatim}

All code follows PEP-8 style guidelines with comprehensive docstrings and type hints.

\section{Ablation Studies}
\label{app:ablation}

\subsection{ECS Component Analysis}

We ablate ECS by computing attention to context at different granularities:

\begin{table}[h]
\centering
\small
\begin{tabular}{lcc}
\toprule
ECS Variant & Correlation with Hall. & AUC \\
\midrule
All layers & TBD & TBD \\
Final 8 layers only & TBD & TBD \\
Middle layers (12-20) & TBD & TBD \\
Per-layer maximum & TBD & TBD \\
\bottomrule
\end{tabular}
\caption{ECS ablation study results.}
\end{table}

\subsection{PKS Component Weights}

We vary PKS component weights to determine optimal combination:

\begin{table}[h]
\centering
\small
\begin{tabular}{cccc|c}
\toprule
$w_c$ & $w_s$ & $w_e$ & Correlation & AUC \\
\midrule
0.4 & 0.3 & 0.3 & TBD & TBD \\
0.5 & 0.3 & 0.2 & TBD & TBD \\
0.33 & 0.33 & 0.33 & TBD & TBD \\
\bottomrule
\end{tabular}
\caption{PKS component weight sensitivity.}
\end{table}

\section{Error Analysis}
\label{app:errors}

\subsection{False Positives}

Cases where ECS < threshold but no hallucination:
\begin{itemize}
    \item Paraphrasing with correct semantics
    \item Valid inferences from context
    \item Common knowledge statements
\end{itemize}

\subsection{False Negatives}

Cases where ECS > threshold but hallucination present:
\begin{itemize}
    \item Hallucinations mixed with factual content
    \item Attention to irrelevant context sections
    \item Misinterpretation despite high attention
\end{itemize}

\section{Annotation Examples}
\label{app:examples}

\subsection{Example 1: Evident Baseless Info}

\textbf{Question}: What are the requirements for high-risk AI systems under the EU AI Act?

\textbf{Context}: "Providers of high-risk AI systems shall, before placing them on the market or putting them into service, carry out a conformity assessment procedure."

\textbf{Response}: "High-risk AI systems must undergo conformity assessment and \textcolor{red}{military deployment certification}."

\textbf{Annotation}: "military deployment certification" marked as Evident Baseless Info (no mention in context).

\textbf{MI Analysis}:
\begin{itemize}
    \item ECS = 0.18 (low)
    \item PKS = 0.76 (high)
    \item Copying heads active: 2/5
    \item Logit Lens: Convergence at layer 28
\end{itemize}

\subsection{Example 2: Subtle Conflict}

\textbf{Question}: Who does the AI Act apply to?

\textbf{Context}: "This Regulation applies to providers placing on the market or putting into service AI systems in the Union."

\textbf{Response}: "The AI Act applies to \textcolor{red}{all AI system developers worldwide}."

\textbf{Annotation}: "all AI system developers worldwide" marked as Subtle Conflict (context specifies providers in Union).

\textbf{MI Analysis}:
\begin{itemize}
    \item ECS = 0.42 (medium)
    \item PKS = 0.58 (medium)
    \item Copying heads active: 4/5
    \item Logit Lens: Convergence at layer 22
\end{itemize}

\section{Statistical Test Details}
\label{app:stats}

\subsection{Normality Tests}

We verify assumptions for parametric tests using Shapiro-Wilk test:

\begin{table}[h]
\centering
\small
\begin{tabular}{lcc}
\toprule
Variable & W statistic & p-value \\
\midrule
ECS (No Hall.) & TBD & TBD \\
ECS (Hall.) & TBD & TBD \\
PKS (No Hall.) & TBD & TBD \\
PKS (Hall.) & TBD & TBD \\
\bottomrule
\end{tabular}
\caption{Normality test results.}
\end{table}

\subsection{Effect Size Interpretations}

Following Cohen's conventions:
\begin{itemize}
    \item Small effect: $|d| \in [0.2, 0.5)$
    \item Medium effect: $|d| \in [0.5, 0.8)$
    \item Large effect: $|d| \geq 0.8$
\end{itemize}

\subsection{Multiple Comparison Correction}

We apply Benjamini-Hochberg FDR correction for $n=$ TBD hypothesis tests:

\begin{table}[h]
\centering
\small
\begin{tabular}{lcc}
\toprule
Test & Original p & Corrected p \\
\midrule
ECS vs Hall. (correlation) & TBD & TBD \\
PKS vs Hall. (correlation) & TBD & TBD \\
ECS diff (t-test) & TBD & TBD \\
PKS diff (t-test) & TBD & TBD \\
\bottomrule
\end{tabular}
\caption{Multiple comparison correction results.}
\end{table}

\end{document}

